---
title: "Pemetaan Kemiskinan di Jawa Tengah dengan Algoritma K-Means"
author: "Deden Istiawan"
output: 
  html_document:
    theme: flatly
    higlight: zenburn
    toc: true
    toc_float:
      collapsed: true
    df_print: paged
bibliography: references.bib
---

```{=html}
<style>
body{
text-align: justify}
</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Pengertian Analisis Cluster

Klastering adalah metode analisis data yang populer dan memainkan peran penting dalam data mining [@jiang2010]. Klastering merupakan sebuah teknik unsupervised learning karena tidak adanya target label dalam prosesnya [@he2012], yang bertujuan untuk mengelompokkan data ke dalam beberapa kelompok atau klaster [@zhang2010] sehingga data dalam satu kelompok memiliki tingkat kemiripan yang maksimum dan data antar kelompok memiliki tingkat kemiripan yang minimum [@xiang2015]. Kemiripan antar data dapat diketahui dengan menghitung jarak antar data [@han2012mining]. Semakin kecil jarak antar data maka semakin tinggi kemiripan antar data tersebut dan sebaliknya [@gan2007]. Analisis klaster telah banyak diaplikasikan dalam berbagai bidang diantaranya riset pasar [@shahbaba2014], kesehatan dan perbankan [@ammar2016], segmentasi citra [@xu2015], pengenalan pola, pengambilan keputusan, machine learning [@yi2010].

Menurut Han dan Kamber [@han2012mining]terdapat banyak algoritma klastering, tetapi secara umum metode-metode utama dalam analisis klaster dapat dikelompokkan berdasarkan metode partisi, metode hirarki, metode berbasis densitas dan metode berbasis grid. Metode klastering yang paling populer adalah metode hirarki dan metode partisi [@deCarvalho2012]. Metode Hirarki mengelompokkan data menjadi seperti struktur pohon [@Krishnasamy2014] dengan cara membuat dekomposisi atau pemecahan objek secara hirarki dengan memisahkan data menjadi subset yang lebih kecil. Metode ini dapat diklasifikasikan menjadi dua, yaitu metode agglomerative dan metode devisive. Metode agglomerative atau disebut juga dengan pendekatan bottom-up, dimulai dengan setiap titik data membentuk kelompok atau klaster yang terpisah. Kemudian secara berturut-turut menggabungkan data yang mempunyai kemiripan hingga semua data berada dalam klaster yang sama. Sedangkan metode devisive atau disebut juga dengan pendekatan top-down, dimana proses pengelompokkan dimulai dengan semua titik data berada dalam satu klaster, kemudian membagi klaster ke dalam klaster yang lebih kecil. Kelebihan metode hirarki adalah tidak membutuhkan informasi jumlah klaster dan juga penentuan nilai-nilai awal sehingga hasil klastering selalu sama , namum membutuhkan waktu komputasi tinggi pada dataset yang besar daripada metode partisi.

# Algoritma K-Means

K-means merupakan salah satu metode hard partition yang banyak digunakan untuk pengelompokan data. Algoritma K-means adalah dasar pengelompokan metode partisi yang dipublikasikan oleh Lloyd dari Bell Telephone Laboratories pada tahun 1957. Penelitian pada K-means dapat ditelusuri kembali ke pertengahan abad yang lalu, yang dilakukan oleh berbagai peneliti diseluruh disiplin ilmu yang berbeda terutama oleh Lloyd (1957), Forgey (1965), Friedman dan Robin (1967) dan MacQueen (1967). K-means dapat didefinisikan sebagai algoritma klastering yang mengelompokan data ke dalam k klaster berdasarkan jarak terdekat data dengan pusat klaster. Algoritma K-means sangat efisien untuk mengelompokan dataset yang besar, kemudahan dalam pengaplikasiannya dan metode yang efisien dalam hal komputasi, menjadi alasan utama popularitas K-means, meskipun telah diusulkan lebih dari 50 tahun yang lalu.

Algoritma K-means mengelompokan objek ke dalam kelompok sehingga objek dalam satu klaster memiliki kemiripan yang tinggi dibandingkan dengan objek di dalam klaster yang berbeda. K-means dimulai dengan menentukan jumlah klaster sebanyak k, kemudian membangkitkan k pusat klaster secara acak. Selanjutnya setiap objek akan dikelompokan berdasarkan jarak terdekat dengan pusat klaster, pusat klaster diperbaharui berdasarkan titik data dalam setiap klaster. Proses ini diulangi sampai kriteria konvergen terpenuhi. Berikut ini adalah tahapan dari algoritma K-means:

1.  Menentukan nilai k sebagai jumlah klaster yang dibentuk.

2.  Memilih k pusat klaster secara acak untuk menjadi pusat klaster awal.

3.  Alokasikan semua data ke pusat klaster terdekat dengan matrik jarak.

4.  Hitung kembali pusat klaster baru berdasarkan data yang mengikuti klaster masing-masing.

5.  Ulangi langkah 3 dan 4 hingga kondisi konvergen tercapai atau tidak ada data yang berpindah dari satu klaster ke klaster yang lainnya.

# Eksperimen Algoritma K-Means
Pada eksprimen ini algoritma K-Means akan digunakan untuk mengelompokan data kemiskinan di Jawa Tengah yang diambil dari website Tim Percepatan Penanggulangan Kemiskinan [(TNP2K)](https://www.tnp2k.go.id/)

## Read Data
Package **readr** menyiapkan fungsi [`read_csv()`](https://readr.tidyverse.org/reference/read_delim.html) untuk import data dari file CSV. Pada kasus ini digunakan data [Data 40% Kemiskinan di jawa Tengah](https://github.com/dedenistiawan/Dataset/blob/main/BDT.csv).

```{r Load_data,warning=FALSE}
library (readr)
urlfile = "https://raw.githubusercontent.com/dedenistiawan/Dataset/main/BDT.csv"

data<-read.csv(url(urlfile), row.names = "Kabupaten")
data
```

## Memeriksa Missing Value

```{r}
colSums(is.na(data))
```

Hasil output di atas menunjukan bahwa tidak *missing value* di semua variabel

## Membuat Matriks Jarak
```{r warning=FALSE, message=FALSE}
#Plot Disatance
library(ggplot2)
library(factoextra)
distance <- get_dist(data)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

Matriks jarak ini berfungsi untuk mengukur jarak antar variabel, semakin merah warnanya maka semakin jauh jarak antar variabel dan semakin biru semakin dekat jarak anntar variabel.

## Menentukan Jumlah *Cluster*
Dalam metode k-means banyaknya klaster ditentukan sendiri oleh pengguna. Maka dari itu perlu dicari jumlah klaster yang optimum yang dapat mengelompokkan objek dengan baik (Perlu diketahui bahwa metode ini relatif subjektif). Salah satu metode yang digunakan adalah Elbow Plot. Elbow Plot merupakan plot antara banyak klaster dengan total within-cluster variation (total dari simpangan per kluster). Banyak klaster yang dipilih adalah bagian “siku” atau titik dimana terdapat penurunan yang tajam sebelum titik tersebut dan disusul penurunan yang tidak tajam setelah titik tersebut. Hal ini karena penambahan jumlah klaster tidak membawa pengaruh banyak atas variasi yang ada di dalam klaster tersebut.

## Membuat Plot *Cluster*
Jumlah klaster yang dibentuk mulai dari 2 sampai 5, untuk melihat sebaran data pada masing-masing *cluster*

```{r}
#use several different values of k
k2 <- kmeans(data, centers = 2, nstart = 25)
k3 <- kmeans(data, centers = 3, nstart = 25)
k4 <- kmeans(data, centers = 4, nstart = 25)
k5 <- kmeans(data, centers = 5, nstart = 25)
```

```{r}
# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = data) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = data) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = data) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = data) + ggtitle("k = 5")
```

```{r warning=FALSE}
library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
```

## Menentukan Jumlah *Cluster*
### Metode Elbow
Metode Elbow merupakan suatu metode yang digunakan untuk menghasilkan informasi dalam menentukan jumlah cluster terbaik dengan cara melihat persentase hasil perbandingan antara jumlah cluster yang akan membentuk siku pada suatu titik. Metode ini memberikan ide/gagasan dengan cara memilih nilai cluster dan kemudian menambah nilai cluster tersebut untuk dijadikan model data dalam penentuan cluster terbaik. Dan selain itu persentase perhitungan yang dihasilkan menjadi pembanding antara jumlah cluster yang ditambah. Hasil persentase yang berbeda dari setiap nilai cluster dapat ditunjukan dengan menggunakan grafik sebagai sumber informasinya. Jika nilai cluster pertama dengan nilai cluster kedua memberikan sudut dalam grafik atau nilainya mengalami penurunan paling besar maka nilai cluster tersebut yang terbaik.

```{r}
#Determining number Optimal Clusters
##Elbow Method
library(ggplot2)
library(factoextra)
fviz_nbclust(data, kmeans, method = "wss") +
  geom_vline(xintercept = 2, linetype = 2)
```

Metode elbow menggunakan nilai total wss (whitin sum square) sebagai penentu 𝐾 optimalnya. Dari gambar di atas terlihat garis mengalami patahan yang membentuk elbow atau siku pada saat 𝐾 = 2. Maka dengan menggunakan metode ini diperoleh 𝐾 optimal pada saat berada di 𝐾 = 2.

### Metode Silhouette
Silhouette Coefficient digunakan untuk melihat kualitas dan kekuatan cluster, seberapa baik suatu objek ditempatkan dalam suatu cluster. Metode ini merupakan gabungan dari metode cohesion dan separation.

```{r}
##Average Silhouette Method
fviz_nbclust(data, kmeans, method = "silhouette")
```

Pendekatan rata-rata nilai metode silhouette untuk menduga kualitas dari klaster yang terbentuk. Semakin tinggi nilai rata-ratanya maka akan semakin baik. Berdasarkan grafik pada gambar di atas banyak klaster optimal yang terbentuk pada  𝐾 = 2.

## Jumlah Klaster Optimal
Dari pendekatan metode elbow dan metode Silhouette di dapatkan jumlah *cluster* optimal adalah K=2. setelah ini dilakukan eksperimen jumlah K=2
```{r}
#Computing k-means clustering
#Compute k-means with k = 2
set.seed(123)
km.res <- kmeans(data, 2, nstart = 25)
# Print the results
print(km.res)
```

Menentukan nilai centroid akhir K-Means untuk melihat karakteristik data
```{r}
aggregate(data, by=list(cluster=km.res$cluster), mean)
```

Menggabungkan hasil *cluster* algoritma K-Means dengan data
```{r}
dd <- cbind(data, cluster = km.res$cluster)
head(dd)
```

Melihat hasil *cluster* akhir pada setiap kabupaten
```{r}
# Cluster number for each of the observations
km.res$cluster
```

Melihat jumlah anggota *cluster*
```{r}
# Cluster size
km.res$size
```

Membuat plot hasil *cluster*
```{r warning=FALSE}
# Cluster means
km.res$centers
fviz_cluster(km.res, data = data)

fviz_cluster(km.res, data = data,
             palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
             ellipse.type = "euclid", # Concentration ellipse
             star.plot = TRUE, # Add segments from centroids to items
             repel = TRUE, # Avoid label overplotting (slow)
             ggtheme = theme_minimal())
```


# Reference
